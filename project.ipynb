{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini prosjekt ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = pd.read_csv(\"data/sales_train.csv\")\n",
    "categories = pd.read_csv(\"data/item_categories.csv\")\n",
    "test_set = pd.read_csv(\"data/test.csv\")\n",
    "items = pd.read_csv(f\"data/items.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(For special people)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# path = \"G:\\My Drive\\AW_Academy\\mini_project_week6\\github repo\\df_feat/\"\n",
    "# df=pd.read_csv(f'{path}df_feat.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_shape_pre = sales.shape\n",
    "\n",
    "# Removing unecessary values\n",
    "sales = sales.query(\"item_cnt_day >= 0 and item_price > 0\")\n",
    "\n",
    "# Removing outliers\n",
    "sales = sales[sales[\"item_cnt_day\"] < sales[\"item_cnt_day\"].quantile(0.99)]\n",
    "sales = sales[sales[\"item_price\"] < sales[\"item_price\"].quantile(0.99)]\n",
    "\n",
    "\n",
    "# Removing rows with shop id not in test set\n",
    "# sales_shops = sales[\"shop_id\"].unique() \n",
    "# test_shops = test_set[\"shop_id\"].unique()\n",
    "# shops = np.intersect1d(sales_shops, test_shops)\n",
    "\n",
    "sales = sales.query(\"shop_id in @shops\")\n",
    "\n",
    "sales_shape_post = sales.shape\n",
    "\n",
    "\n",
    "# Resetting index after removing rows\n",
    "sales.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Adding test-data to main dataframe for easy transformation\n",
    "test_set[\"date_block_num\"] = 34\n",
    "test_set.index=np.arange(2928493, 2928493+test_set.shape[0])\n",
    "\n",
    "sales = pd.concat([sales, test_set.drop(columns=[\"ID\"])])\n",
    "sales.fillna(0, inplace=True)\n",
    "\n",
    "# Converting date column to datetime\n",
    "sales[\"date\"] = pd.to_datetime(sales[\"date\"], dayfirst=True)\n",
    "\n",
    "print(sales_shape_pre)\n",
    "print(sales_shape_post)\n",
    "print(f\"-{sales_shape_pre[0] - sales_shape_post[0]} rows\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales[\"month\"] = sales[\"date\"].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping by each month, shop_id and item_id -> goal of prediction\n",
    "# Also removes date column\n",
    "sales = sales.groupby(by=[\"date_block_num\", \"shop_id\", \"item_id\"], as_index=False)\n",
    "sales = sales.agg({\"item_cnt_day\":\"sum\", \"item_price\":\"mean\", \"month\":\"min\"})\n",
    "\n",
    "sales.rename(columns={\"item_cnt_day\":\"item_cnt_month\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each shops total sales for prior month\n",
    "shop_tot_sales = sales[[\"date_block_num\", \"shop_id\", \"item_cnt_month\"]].groupby(\n",
    "    by=[\"date_block_num\", \"shop_id\"], as_index=False).sum()\n",
    "\n",
    "shop_tot_sales.rename(columns={\"item_cnt_month\":\"shop_tot_month\"}, inplace=True)\n",
    "\n",
    "shop_tot_sales[\"date_block_num\"] += 1\n",
    "\n",
    "sales = sales.merge(shop_tot_sales, how=\"left\", on=[\"date_block_num\", \"shop_id\"])\n",
    "\n",
    "# Freeing memory\n",
    "del shop_tot_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_cnt_offset(n_steps):\n",
    "    \"\"\" Adds `item_cnt_month` to `sales` df with offset of `n_steps`.\n",
    "    \"\"\"\n",
    "\n",
    "    temp = sales[[\"date_block_num\", \"item_id\", \"shop_id\", \"item_cnt_month\"]].copy()\n",
    "    \n",
    "    temp[\"date_block_num\"] += n_steps\n",
    "    \n",
    "    temp.rename(columns={\"item_cnt_month\":f\"item_cnt_month_offset_{n_steps}\"}, inplace=True)\n",
    "\n",
    "    return sales.merge(temp, how=\"left\", on=[\"date_block_num\", \"item_id\", \"shop_id\"])    \n",
    "\n",
    "# Offset numbers yielding highest feature importance\n",
    "sales = add_cnt_offset(1)\n",
    "sales = add_cnt_offset(2)\n",
    "sales = add_cnt_offset(3)\n",
    "sales = add_cnt_offset(4)\n",
    "# sales = add_cnt_offset(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing and merging items-df for item_category_id column\n",
    "items.drop(columns=[\"item_name\"], inplace=True)\n",
    "sales = sales.merge(items, how=\"left\", on=\"item_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating total sales for each category\n",
    "category_tot_sales = sales[[\"date_block_num\", \"item_category_id\", \"item_cnt_month\"]].groupby(\n",
    "    by=[\"date_block_num\", \"item_category_id\"], as_index=False).sum()\n",
    "\n",
    "category_tot_sales.rename(columns={\"item_cnt_month\":\"category_tot_count\"}, inplace=True)\n",
    "\n",
    "category_tot_sales[\"date_block_num\"] += 1\n",
    "\n",
    "sales = sales.merge(category_tot_sales, how=\"left\", on=[\"date_block_num\", \"item_category_id\"])\n",
    "\n",
    "# Freeing memory\n",
    "del category_tot_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The date_block where the first sale of each item happened\n",
    "# Could also be the day of the year where the first sale happened, might yield better results?\n",
    "first_sales = sales.groupby(\"item_id\", as_index=False).agg({\"date_block_num\":\"min\"})\n",
    "\n",
    "first_sales.columns=[\"item_id\", \"first_sale_date_block\"]\n",
    "\n",
    "sales = sales.merge(first_sales, how=\"left\", on=\"item_id\")\n",
    "\n",
    "# Free memory\n",
    "del first_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sin transform of date_block_num (did not improve performance of model)\n",
    "# sales[\"date_block_num\"] = np.sin(sales[\"date_block_num\"])\n",
    "# sales[\"date_block_num\"].sample(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import OPTICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_df = sales[[\"shop_id\", \"item_cnt_month\", \"date_block_num\"]].groupby(by=[\"date_block_num\", \"shop_id\"], as_index=False).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans()\n",
    "cluster_df[\"shop_cnt_cluster\"] = kmeans.fit_predict(cluster_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = sales.merge(cluster_df[[\"shop_id\", \"shop_cnt_cluster\", \"date_block_num\"]], how=\"left\", on=[\"date_block_num\",\"shop_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optics = OPTICS()\n",
    "cluster_df = sales[[\"item_category_id\", \"item_cnt_month\", \"date_block_num\"]].groupby(by=[\"item_category_id\", \"date_block_num\"], as_index=False).sum()\n",
    "cluster_df[\"item_category_cluster\"] = optics.fit_predict(cluster_df)\n",
    "sales = sales.merge(cluster_df[[\"item_category_id\",\"item_category_cluster\", \"date_block_num\"]], how=\"left\", on=[\"date_block_num\", \"item_category_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove uneeded column\n",
    "del sales[\"item_price\"]\n",
    "\n",
    "# Fill nan values\n",
    "sales.fillna(0, inplace=True)\n",
    "sales.sample(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using month 33 as testing data, change to make predictions over other months\n",
    "test_month = 33\n",
    "\n",
    "train = sales.query(f\"date_block_num < {test_month}\")\n",
    "test = sales.query(f\"date_block_num == {test_month}\")\n",
    "\n",
    "\n",
    "# Predict-target is item_cnt_month\n",
    "y_train = train[\"item_cnt_month\"]\n",
    "x_train = train.drop(columns=[\"item_cnt_month\"])\n",
    "\n",
    "y_test = test[\"item_cnt_month\"]\n",
    "x_test = test.drop(columns=[\"item_cnt_month\"])\n",
    "\n",
    "\n",
    "\n",
    "# Random, test/train split\n",
    "## y = sales[\"item_cnt_month\"]\n",
    "## x = sales.drop(columns=[\"item_cnt_month\"])\n",
    "\n",
    "# #x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=420)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling\n",
    "Testing with both `LinearRegression` and `XGBRegressor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining util functions\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "\n",
    "if not \"models\" in os.listdir():\n",
    "    os.mkdir(\"models\")\n",
    "if not \"predictions\" in os.listdir():\n",
    "    os.mkdir(\"predictions\")\n",
    "\n",
    "mse = mean_squared_error\n",
    "def clp(x):\n",
    "    \"\"\"Clips values between 0 and 20\"\"\"\n",
    "    return np.clip(x, 0 ,20)\n",
    "\n",
    "def score_model(model=None, metric=False):\n",
    "    \"\"\"Scores model, if `model` is `None` makes naive prediction. \n",
    "    If `metric` is `True`, returns scores as tuple else only prints scores.\"\"\"\n",
    "    \n",
    "    if not model:\n",
    "        train_score = mse(clp(y_train), clp(x_train[\"item_cnt_month_offset_1\"]), squared=False)\n",
    "        test_score = mse(clp(y_test), clp(x_test[\"item_cnt_month_offset_1\"]), squared=False)\n",
    "        \n",
    "        print(\"train: \", train_score)\n",
    "        print(\"test: \", test_score)\n",
    "        \n",
    "        if metric:\n",
    "            return train_score, test_score\n",
    "    \n",
    "    elif model:\n",
    "        train_score = mse(clp(y_train), clp(model.predict(x_train)), squared=False)\n",
    "        test_score = mse(clp(y_test), clp(model.predict(x_test)), squared=False)\n",
    "        \n",
    "        print(\"train: \", train_score)\n",
    "        print(\"test: \", test_score)\n",
    "        \n",
    "        if metric:\n",
    "            return train_score, test_score\n",
    "\n",
    "\n",
    "def save_final_pred(model):\n",
    "    \"\"\"Makes and saves predictions for `test_set` (date_block_num 34).\n",
    "    \"\"\"\n",
    "    test = sales.query(\"date_block_num == 34\")\n",
    "    \n",
    "    x_test = test.drop(columns=[\"item_cnt_month\"])\n",
    "    \n",
    "    pred = clp(model.predict(x_test))\n",
    "\n",
    "    if pred.shape[0] != 214200:\n",
    "        raise Exception(f\"Prediction must be 214200 rows, is: {pred.shape[0]} rows\") \n",
    "    \n",
    "    df = pd.DataFrame({\"ID\":test_set[\"ID\"], \"item_cnt_month\":pred})\n",
    "    \n",
    "    df.to_csv(f\"predictions/final_pred_{model.__class__.__name__}.csv\", index=False)\n",
    "\n",
    "def save_model_metrics(model):\n",
    "    \"\"\"Saves models paramters, scores and features used to predict y.\n",
    "    \"\"\"\n",
    "\n",
    "    path = f\"models/{model.__class__.__name__}.json\"\n",
    "    \n",
    "    models = os.listdir(\"models\")\n",
    "    \n",
    "    if f\"{model.__class__.__name__}.json\" not in models:\n",
    "        with open(path, \"w\") as file:\n",
    "            file.write(\"{}\")\n",
    "    \n",
    "    with open(path, \"r\") as file:\n",
    "        model_metrics = json.load(file)\n",
    "    \n",
    "    model_params = model.get_params()\n",
    "\n",
    "    train_score, test_score = score_model(model, metric=True)\n",
    "    \n",
    "    model_metrics[int(time.time())] = {\n",
    "        \"scores\":{\"train\":train_score, \"test\":test_score},\n",
    "        \"params\": model_params,\n",
    "        \"features\": list(x_train.columns)\n",
    "    }\n",
    "\n",
    "    with open(path, \"w\") as file:\n",
    "        json.dump(model_metrics, file)\n",
    "\n",
    "def save_results(model):\n",
    "    \"\"\"Creates and saves final prediction (test_set) and metrics for model.\n",
    "    \n",
    "    See:\n",
    "    - `save_final_pred()`\n",
    "    - `save_model_metrics()`\n",
    "    \"\"\"\n",
    "    save_final_pred(model)\n",
    "    save_model_metrics(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(x_train, y_train)\n",
    "\n",
    "score_model(lr)\n",
    "\n",
    "# Uncomment to automatically save results of each run\n",
    "# save_results(lr)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knr = KNeighborsRegressor(n_neighbors=15)\n",
    "# knr.fit(x_train, y_train)\n",
    "\n",
    "# score_model(knr)\n",
    "\n",
    "# Uncomment to automatically save results/metrics of each run\n",
    "## save_results(knr)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbr = XGBRegressor(\n",
    "    max_depth=8,\n",
    "    n_estimators=100,\n",
    "    early_stopping_rounds = 8,\n",
    "    eval_metric=\"rmse\",\n",
    "    gamma=0.1,\n",
    "\n",
    "    random_state=420   \n",
    ")\n",
    "\n",
    "xgbr.fit(\n",
    "    x_train, \n",
    "    y_train, \n",
    "    eval_set=[(x_train, y_train), (x_test, y_test)], \n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "\n",
    "# Uncomment to automatically save results of each run\n",
    "# save_results(xgbr)\n",
    "\n",
    "score_model(xgbr)\n",
    "\n",
    "# Feature importances of XGBRegressor model\n",
    "\n",
    "feature_importances = {fn:fi for fn, fi in zip(xgbr.feature_names_in_, xgbr.feature_importances_)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "test_score = np.array(xgbr.evals_result_[\"validation_1\"][\"rmse\"])\n",
    "train_score = np.array(xgbr.evals_result_[\"validation_0\"][\"rmse\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.barh(list(feature_importances.keys()), feature_importances.values(), log=True)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(test_score.shape[0]), test_score)\n",
    "plt.plot(np.arange(train_score.shape[0]), train_score)\n",
    "plt.legend([\"test_rmse\", \"train_rmse\"])\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compression_opts = dict(method='zip',\n",
    "#                         archive_name='df_feat.csv')  \n",
    "\n",
    "# sales.to_csv('df_feat.zip', index=False,\n",
    "#           compression=compression_opts)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_test[\"pred_cnt_month\"] = lr.predict(x_test.drop(columns=[\"item_cnt_actual\", \"pred_cnt_month\"]))\n",
    "# x_test[\"item_cnt_actual\"] = y_test\n",
    "# x_test.to_csv(\"data_XGBRegressor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from xgboost.plotting import plot_importance, plot_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(400, 400))\n",
    "# plot_tree(xgbr, ax = ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e9caa910d20d102cdafc73cd2b067d6e1cf42a3b62a36b0e4e3a15dd5f2f5418"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
